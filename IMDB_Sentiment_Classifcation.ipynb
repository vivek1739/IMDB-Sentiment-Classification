{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "51.A IMDB Sentiment Classifcation.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5Lw6Yz1_p0En",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Intro\n",
        "- LSTM are tricky to get them to work"
      ]
    },
    {
      "metadata": {
        "id": "krZK1T83p0Eq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HpDizHVWp0Ey",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0ae9d8ee-cdd1-4a66-e288-ceda7bc1bf28",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532425129012,
          "user_tz": -330,
          "elapsed": 9660,
          "user": {
            "displayName": "Vivek Kumar",
            "photoUrl": "//lh6.googleusercontent.com/-M_uuoLvcedc/AAAAAAAAAAI/AAAAAAAAASo/dW13zAextDg/s50-c-k-no/photo.jpg",
            "userId": "112122627751315204755"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Credits: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
        "# Refer: https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words = top_words)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/datasets/imdb.py:49: UserWarning: The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `load_data` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xe0m2PoCp0E7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "048dc4e0-5c7e-4039-a3b0-679b5db1b08b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532425130035,
          "user_tz": -330,
          "elapsed": 974,
          "user": {
            "displayName": "Vivek Kumar",
            "photoUrl": "//lh6.googleusercontent.com/-M_uuoLvcedc/AAAAAAAAAAI/AAAAAAAAASo/dW13zAextDg/s50-c-k-no/photo.jpg",
            "userId": "112122627751315204755"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(X_train[1])\n",
        "print(type(X_train[1]))\n",
        "print(len(X_train[1]))\n",
        "print(\"-------------------\")\n",
        "print(X_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
            "<class 'list'>\n",
            "189\n",
            "-------------------\n",
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "idnFS8Czp0E-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Knowing the IMDB keras data\n",
        "- 50K data of reviews\n",
        "- each review is sequence of words\n",
        "    - x1 = x11,x22... and yi\n",
        "       \n",
        "- First build V = a set or corpus of all the words in all the review\n",
        "    1. for each word compute frequency of the word\n",
        "    2. sort by fequency\n",
        "        - ex\n",
        "            - The = 50K\n",
        "            - a = 40K\n",
        "    3. give Rank to the words, ex. Whenever we see The replace with 1, whenever we see 'a' replace it with 2\n",
        "        - .'. 1 is for most freq words and we will take top 5000 words.\n",
        "        - let a review has a word having rank 5001, discard that word\n",
        "        \n",
        "- let say we have x1= x11,x12...x1,189\n",
        "- x2 = x21,x22,..,x290\n",
        "- so we have words of diff length\n",
        "    - So we will add padding\n",
        "    - so it will convert all x1 to 600 length\n",
        "    - this does prepadding, ie. 0 before and data after till it is 600 dimensional\n",
        "- if review has > 600 words, discard more than 600\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Upkx16kQp0E-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "b3d71ba5-470a-4397-84c9-b8477a04356f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532425132979,
          "user_tz": -330,
          "elapsed": 2308,
          "user": {
            "displayName": "Vivek Kumar",
            "photoUrl": "//lh6.googleusercontent.com/-M_uuoLvcedc/AAAAAAAAAAI/AAAAAAAAASo/dW13zAextDg/s50-c-k-no/photo.jpg",
            "userId": "112122627751315204755"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# truncate and/or pad input sequences\n",
        "max_review_length = 600\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_train[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 600)\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    1  194 1153  194    2   78  228    5    6\n",
            " 1463 4369    2  134   26    4  715    8  118 1634   14  394   20   13\n",
            "  119  954  189  102    5  207  110 3103   21   14   69  188    8   30\n",
            "   23    7    4  249  126   93    4  114    9 2300 1523    5  647    4\n",
            "  116    9   35    2    4  229    9  340 1322    4  118    9    4  130\n",
            " 4901   19    4 1002    5   89   29  952   46   37    4  455    9   45\n",
            "   43   38 1543 1905  398    4 1649   26    2    5  163   11 3215    2\n",
            "    4 1153    9  194  775    7    2    2  349 2637  148  605    2    2\n",
            "   15  123  125   68    2    2   15  349  165 4362   98    5    4  228\n",
            "    9   43    2 1157   15  299  120    5  120  174   11  220  175  136\n",
            "   50    9 4373  228    2    5    2  656  245 2350    5    4    2  131\n",
            "  152  491   18    2   32    2 1212   14    9    6  371   78   22  625\n",
            "   64 1382    9    8  168  145   23    4 1690   15   16    4 1355    5\n",
            "   28    6   52  154  462   33   89   78  285   16  145   95]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QAvMD124p0FB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "why pad ?\n",
        "- we use RNN and LSTM bcz we can have different length inputs. But we are we doing padding here \n",
        "    - ex. let x1 = x11,x12,....x1 189\n",
        "    - x2 = x21,x22,....x2 200\n",
        "    - x3 = x31,x32,....x3 150\n",
        "- initially we will send x1 to the nodes, then x2 and then x3 in every time sequence.\n",
        "    - this is like SGD with batch size 1 which is too slow\n",
        "    - ie. x11 to 1st node , x12 to 2nd node .....\n",
        "- lets say,we perform sgd with batch size =5. \n",
        "    - here x11,x21,x31,x41,x51 to 1st node\n",
        "    - x12,x22,x32,x42,x52 to 2nd node\n",
        "    - to perform batch update we need each of sequence to have same length. \n",
        "- So padding allows batch operation and faster training\n",
        "- For text, we will generally do padding.\n",
        "\n",
        "#### Create model\n",
        "- 1st layer is embedding layer\n",
        "    - Embedding layer takes indices and returns vectors\n",
        "    - they are used a lot in nlp tasks\n",
        "    - for each of our word in review we can represent using 5000-dim one hot encoded vector\n",
        "        - word2vec is an example of embedding\n",
        "        - so it will take a word and give a vector representation of the word\n",
        "    - why to do embedding and not w2v?\n",
        "        - for every word we have static word2vec and we are not learning as per task\n",
        "    - params\n",
        "        - input - 5000\n",
        "        - output - 32\n",
        "        - .'. num of params 160K\n",
        "        - it has 32 activations so we wil get 32 output\n",
        "\n",
        "- LSTM (100) means we have 100 LSTMs\n",
        "    - each of LSTM takes the same 32 dim vector\n",
        "    - each of LSTM generate output\n",
        "    - each LSTM takes 32 dim input gives o/p and has a feedback loop\n",
        "    - params :\n",
        "        - m = 32 inputs and 100 outputs and each giving scalar\n",
        "        - n = total o/p size 100\n",
        "        - #params = 4( nm + n^2 + n)\n",
        "            - last n is for bias\n",
        "            - lstm in keras has by default bias terms\n",
        "            - = 53200\n",
        "- now connect all 100 + 1 bias term to a signmoid to get yi^ which is binary\n",
        "    - params : 101\n",
        "- loss is binary cross entropy"
      ]
    },
    {
      "metadata": {
        "id": "6acVXdm7p0FC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7789b512-a76b-4d1c-cab2-ddafd1ee6cd3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532425162590,
          "user_tz": -330,
          "elapsed": 864,
          "user": {
            "displayName": "Vivek Kumar",
            "photoUrl": "//lh6.googleusercontent.com/-M_uuoLvcedc/AAAAAAAAAAI/AAAAAAAAASo/dW13zAextDg/s50-c-k-no/photo.jpg",
            "userId": "112122627751315204755"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "#Refer: https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 600, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6wlkQXNvp0FF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "33ce7ed9-17e0-4f5d-c8e7-4a740bb795af",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532433963865,
          "user_tz": -330,
          "elapsed": 76380,
          "user": {
            "displayName": "Vivek Kumar",
            "photoUrl": "//lh6.googleusercontent.com/-M_uuoLvcedc/AAAAAAAAAAI/AAAAAAAAASo/dW13zAextDg/s50-c-k-no/photo.jpg",
            "userId": "112122627751315204755"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, nb_epoch=10, batch_size=64)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 754s 30ms/step - loss: 0.2870 - acc: 0.8859\n",
            "Epoch 2/10\n",
            "20096/25000 [=======================>......] - ETA: 2:27 - loss: 0.2296 - acc: 0.9102"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 754s 30ms/step - loss: 0.2302 - acc: 0.9098\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 753s 30ms/step - loss: 0.2481 - acc: 0.9004\n",
            "Epoch 4/10\n",
            " 4352/25000 [====>.........................] - ETA: 10:19 - loss: 0.1734 - acc: 0.9373"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 752s 30ms/step - loss: 0.1816 - acc: 0.9323\n",
            "Epoch 5/10\n",
            "24704/25000 [============================>.] - ETA: 8s - loss: 0.1487 - acc: 0.9454 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 753s 30ms/step - loss: 0.1488 - acc: 0.9453\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 749s 30ms/step - loss: 0.1414 - acc: 0.9486\n",
            "Epoch 7/10\n",
            " 5696/25000 [=====>........................] - ETA: 9:36 - loss: 0.1036 - acc: 0.9628"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 751s 30ms/step - loss: 0.1171 - acc: 0.9589\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 755s 30ms/step - loss: 0.2678 - acc: 0.8851\n",
            "Epoch 9/10\n",
            "  128/25000 [..............................] - ETA: 12:20 - loss: 0.4913 - acc: 0.7344"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 756s 30ms/step - loss: 0.3090 - acc: 0.8634\n",
            "Epoch 10/10\n",
            "22656/25000 [==========================>...] - ETA: 1:10 - loss: 0.1614 - acc: 0.9378"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 750s 30ms/step - loss: 0.1617 - acc: 0.9380\n",
            "Accuracy: 86.09%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ogi4dO60L2bb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "2ad1fba5-5011-4255-da6a-51a67873d1a4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532435539004,
          "user_tz": -330,
          "elapsed": 1215,
          "user": {
            "displayName": "Vivek Kumar",
            "photoUrl": "//lh6.googleusercontent.com/-M_uuoLvcedc/AAAAAAAAAAI/AAAAAAAAASo/dW13zAextDg/s50-c-k-no/photo.jpg",
            "userId": "112122627751315204755"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "epochs_list = list(range(1,11))\n",
        "import matplotlib.pyplot as plt\n",
        "train_acc = history.history['acc']\n",
        "train_loss = history.history['loss']\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(epochs_list,train_loss,label=\"train loss\")\n",
        "plt.xlabel(\" Epochs \")\n",
        "plt.ylabel(\" Loss \")\n",
        "plt.legend()\n",
        "plt.title(\" 5x5 Simple model : Loss vs epochs\")\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAADfCAYAAACZHjo7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f386290b908>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "epF0iNLWL2VZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7318d97b-1840-4931-bc0c-212ea286566f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532435514946,
          "user_tz": -330,
          "elapsed": 769,
          "user": {
            "displayName": "Vivek Kumar",
            "photoUrl": "//lh6.googleusercontent.com/-M_uuoLvcedc/AAAAAAAAAAI/AAAAAAAAASo/dW13zAextDg/s50-c-k-no/photo.jpg",
            "userId": "112122627751315204755"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "SdoA7bmDp0FI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: Each LSTM cell may learn something diff in data"
      ]
    }
  ]
}